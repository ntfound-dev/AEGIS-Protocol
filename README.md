# Aegis Protocol - A Decentralized Disaster Response Framework

[![tag:innovationlab](https://img.shields.io/badge/innovationlab-3D88D3)](https://dorahacks.io/buidl/13593)

Aegis Protocol is an autonomous digital institution that serves as a global safety net for humanity. This project combines decentralized AI with blockchain technology for fast, transparent, and decentralized disaster response.

---

## ğŸ› Architecture

The Aegis Protocol architecture consists of two main layers that communicate with each other:

1. **Intelligence Layer (Fetch.ai):** Functions as the "nervous system" of the protocol. This decentralized network of autonomous AI agents proactively monitors global data to detect and validate disasters.
2. **Execution Layer (Internet Computer):** Functions as the "backbone" of execution and trust. Running on Internet Computer, this layer manages DAO creation, fund treasury, voting, and on-chain reputation systems.

- **Detailed Architecture Diagram:** [View here](./docs/diagrams/endgame_architecture.mermaid)

---

## âœ¨ Main Features & Innovation

### ICP Features Used
- **Canister Smart Contracts:** All backend logic, including DAO and insurance vaults, deployed as canisters running entirely on-chain.
- **"Reverse Gas" Model:** Users (donors, NGOs) can interact with the application without paying gas fees, removing adoption barriers.
- **On-Chain Web Serving:** Capability to host frontend interfaces directly from canisters, creating fully decentralized applications.
- **On-Chain Identity & Assets:** Managing identity (DID) and reputation assets (SBTs) permanently on the blockchain.

### Fetch.ai Features Used
- **uAgents (Micro-agents):** Building autonomous AI agents (oracle, validator, action) that can communicate and act independently.
- **Agentverse / ASI:One:** Providing a platform for communication and interaction between agents, including implementation of **Chat Protocol** needed for demo.
- **Decentralized AI Network:** Leveraging the Fetch.ai network as a foundation for intelligent and censorship-resistant decentralized oracles.

---

## ğŸ¤– Fetch.ai Agent Details (For Judges)

Here are the details of the agents running on Fetch.ai, according to hackathon requirements.

- **Oracle Agent (oracle_agent_usgs)**
  - **Address:** Address will be generated when the agent is run.
  - **Task:** Monitor external data sources (USGS) to detect disaster anomalies.

- **Validator Agent (validator_agent_alpha)**
  - **Address:** `agent1q2gwxq52k8wecuvj3sksv9sszefaqpmq42u0mf6z0q5z4e0a9z0wz9z0q`
  - **Task:** Receive raw data, perform validation, and reach consensus. This agent implements **Fetch.ai Chat Protocol** and can interact through Agentverse/ASI:One.

- **Action Agent (action_agent_bridge)**
  - **Address:** Address will be generated when the agent is run.
  - **Task:** Receive consensus results and call smart contracts on Internet Computer.

---

## ğŸš€ How to Run the Project (Local Development) â€“ WSL Version

This project uses **Docker Compose** to simplify the setup and execution process.
**âš ï¸ All `bash` commands are run in different terminals (different WSL tabs/instances).**

---

### 1. Prerequisites

Make sure your device has the following installed:

- Docker & Docker Compose
- Git
- (Optional, if using WSL) install `dos2unix` to avoid line ending issues (CRLF) on `.sh` files:

```bash
sudo apt update && sudo apt install dos2unix -y
```

---

### 2. Clone Repository

```bash
git clone https://github.com/ntfound-dev/AEGIS-Protocol.git
cd AEGIS-Protocol
```

---

### 3. Line Ending Conversion (WSL/Windows Users Only)

If you cloned this repo on Windows and then run it on WSL, some `.sh` files might not be executable due to line ending format. Run:

```bash
dos2unix scripts/*.sh
```

---

### 4. Create Environment File

Create a `.env` file in the root directory with the following content:

```bash
# API keys for external services (e.g., OpenAI, etc.)
# Get your own API keys and insert them here. NEVER share your .env file.
ASI_ONE_API_KEY=

# Canister name on Internet Computer
CANISTER_NAME=event_factory

# Seed phrases for generating agent private keys.
# Generate new seed phrases for each deployment. DO NOT use these examples.
# You can use online mnemonic generators or dedicated libraries for this.
VALIDATOR_AGENT_SEED=""
ACTION_AGENT_SEED=""
ORACLE_AGENT_SEED=""

# Agent addresses will be generated automatically when agents first run.
# After running docker compose up, copy agent addresses from logs and paste here for subsequent runs.
VALIDATOR_AGENT_ADDRESS=
ACTION_AGENT_ADDRESS=
ORACLE_AGENT_ADDRESS=

# Chain / Internet Computer configuration
# These defaults are usually suitable for local development.
CHAIN_ID="dorado-1"
ICP_URL="http://host.docker.internal:4943"
CANISTER_IDS_PATH="/app/dfx-local/canister_ids.json"
IDENTITY_PEM_PATH="/app/identity.pem"
```

The `.env` file must be located in the **root project**.

---

### 5. Identity & Principal (**Run this first**)

To get the **principal identity**, run:

```bash
dfx identity get-principal
```

When prompted for password, use default: `Mei2000`.

> âš ï¸ **Note**: This step must be done first before running other services.

---

### 6. Create Action Agent Identity Keys

Open a **new WSL terminal**, then run:

```bash
bash scripts/generate-keys.sh
```

---

### 7. Run All Manual Scripts (Required, Separate Terminals)

Every component in this project is interdependent and must be run in parallel. Therefore, **all the following scripts must be run one by one in different WSL terminals (separate)**.

Open three separate WSL terminals, then run the following commands in sequence (each in its own terminal):

**Terminal 1:**
```bash
bash ./scripts/deploy-blockchain.sh
```

**Terminal 2:**
```bash
bash ./scripts/run-agents.sh
```

**Terminal 3:**
```bash
bash ./scripts/run-frontend.sh
```

> âš ï¸ **Note:** Do not run these scripts in the same terminal, as all these processes are part of one unified project that must run simultaneously.

---

### 8. Run Backend Services (Docker) â€“ Optional / Last

Since Docker currently has some minor errors, this step is moved to the end.
If you want to try, run in a **new WSL terminal**:

```bash
# Build main service
docker-compose build dfx-replica

# Run all services
docker-compose up --build
```

---

## ğŸ“‚ Project Structure
```
aegis-protocol/
â”œâ”€â”€ .gitignore                    # Ignore unnecessary files (build artifacts, .env, .pem, etc.)
â”œâ”€â”€ README.md                     # Main documentation: installation, setup, and running each service
â”œâ”€â”€ Dockerfile                    # Docker configuration for root project
â”œâ”€â”€ dfx.json                      # Main configuration file for DFINITY SDK (dfx)
â”œâ”€â”€ mops.toml                     # Motoko package manager configuration
â”œâ”€â”€ .env                          # Environment variables (generated from env.example)
â”œâ”€â”€ env.example                   # Environment file template
â”œâ”€â”€ identity.pem                  # Main identity key (ignored by gitignore)
â”œâ”€â”€ install-mops.sh               # Script to install Motoko package manager
â”œâ”€â”€ .ic-assets.json5              # Internet Computer assets configuration
â”‚
â”œâ”€â”€ docs/                         # Complete project documentation
â”‚   â”œâ”€â”€ architecture.md           # In-depth technical architecture explanation
â”‚   â”œâ”€â”€ concepts.md               # Vision and core concepts explanation of Aegis Protocol
â”‚   â”œâ”€â”€ diagram.md                # Diagram documentation
â”‚   â”œâ”€â”€ diagram.mermaid           # Mermaid diagram file
â”‚   â””â”€â”€ problem_and_solution_technical.md  # Technical problem and solution analysis
â”‚
â”œâ”€â”€ frontend/                     # <------------ [ FOR FRONTEND TEAM ]
â”‚   â”œâ”€â”€ index.html                # Main page for Dashboard Demo
â”‚   â”œâ”€â”€ main.js                   # Main frontend logic (replaces script.js)
â”‚   â”œâ”€â”€ style.css                 # Page styling
â”‚   â”œâ”€â”€ package.json              # Node.js dependencies for frontend
â”‚   â”œâ”€â”€ package-lock.json         # Dependencies lock file
â”‚   â”œâ”€â”€ vite.config.js            # Vite configuration for development server
â”‚   â””â”€â”€ node_modules/             # Node.js modules (auto-generated)
â”‚
â”œâ”€â”€ src/                          # <------------ [ FOR BLOCKCHAIN TEAM ]
â”‚   â”œâ”€â”€ declarations/             # Auto-generated TypeScript/JavaScript bindings
â”‚   â”‚   â”œâ”€â”€ did_sbt_ledger/       # TypeScript declarations for DID SBT Ledger
â”‚   â”‚   â”œâ”€â”€ event_dao/            # TypeScript declarations for Event DAO
â”‚   â”‚   â”œâ”€â”€ event_factory/        # TypeScript declarations for Event Factory
â”‚   â”‚   â”œâ”€â”€ frontend/             # TypeScript declarations for Frontend canister
â”‚   â”‚   â””â”€â”€ insurance_vault/      # TypeScript declarations for Insurance Vault
â”‚   â”œâ”€â”€ did_sbt_ledger/
â”‚   â”‚   â””â”€â”€ main.mo               # Canister for identity and reputation (DID & SBT)
â”‚   â”œâ”€â”€ event_dao/
â”‚   â”‚   â”œâ”€â”€ main.mo               # Template canister for each disaster
â”‚   â”‚   â”œâ”€â”€ event_defs.mo         # Event definitions and data structures
â”‚   â”‚   â””â”€â”€ types.mo              # Type definitions for Event DAO
â”‚   â”œâ”€â”€ event_factory/
â”‚   â”‚   â”œâ”€â”€ main.mo               # Canister (factory) for creating EventDAO
â”‚   â”‚   â””â”€â”€ types.mo              # Type definitions for Event Factory
â”‚   â”œâ”€â”€ insurance_vault/
â”‚   â”‚   â””â”€â”€ main.mo               # Parametric insurance vault canister
â”‚   â””â”€â”€ types/                    # Shared type definitions
â”‚
â”œâ”€â”€ services/                     # Backend services and deployment
â”‚   â”œâ”€â”€ ai_agent/                  # <------------ [FOR AI TEAM]
â”‚   â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies (uagents, requests, ic-py)
â”‚   â”‚   â”œâ”€â”€ Dockerfile            # Recipe for creating Docker container for agents
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration for backend services
â”‚   â”‚   â”œâ”€â”€ .env.example          # Backend environment template
â”‚   â”‚   â”œâ”€â”€ persistent/           # Persistent data for development
â”‚   â”‚   â”‚   â”œâ”€â”€ dfx-local/        # Local dfx data
â”‚   â”‚   â”‚   â””â”€â”€ identity.pem      # Identity key for backend agents
â”‚   â”‚   â””â”€â”€ agents/               # All AI agents folder
â”‚   â”‚       â”œâ”€â”€ oracle_agent.py   # Agent that monitors real-world data
â”‚   â”‚       â”œâ”€â”€ validator_agent.py # Agent that validates disaster data
â”‚   â”‚       â”œâ”€â”€ action_agent.py   # Agent that bridges to ICP
â”‚   â”‚       â””â”€â”€ chatbotrepair/    # Chatbot repair agents
â”‚   â”‚           â”œâ”€â”€ asi_one.py    # ASI.One integration agent
â”‚   â”‚           â””â”€â”€ functions.py  # Utility functions for chatbot
â”‚   â””â”€â”€ dfx/
â”‚       â””â”€â”€ Dockerfile            # Docker configuration for DFX service
â”‚
â”œâ”€â”€ .dfx/                         # Folder automatically created by dfx (build artifacts)
â”‚   â”œâ”€â”€ local/                    # Local deployment artifacts
â”‚   â””â”€â”€ network/                  # Network deployment artifacts
â”‚
â””â”€â”€ scripts/                      # Automation scripts
    â”œâ”€â”€ deploy-blockchain.sh      # Script to deploy all canisters
    â”œâ”€â”€ run-agents.sh             # Script to run all Python agents
    â”œâ”€â”€ run-frontend.sh           # Script to run frontend development server
    â””â”€â”€ generate-keys.sh          # Script to create new identity.pem
```

---

## ğŸ¯ Future Plans (Post-Hackathon)

- **Q4 2025:** Testnet Launch, inviting the first 5 NGO partners for trials.
- **Q1 2026:** Security Audit & Mainnet Beta Launch with Flutter frontend.
- **Q2 2026:** $AEGIS Tokenomics Development for governance and staking.
- **Q3 2026:** Global Expansion through partnerships with international humanitarian agencies.

## ğŸ§— Challenges During Hackathon

1. **Ecosystem Interoperability:** Designing reliable communication protocols between Python agents on Fetch.ai with Motoko canisters on ICP.
2. **Real-time Simulation:** Integrating data sources for disaster detection simulation by Oracle Agent.
3. **Team Workflow:** Coordinating teams with different expertise (Blockchain, AI, Frontend) in a short time.
